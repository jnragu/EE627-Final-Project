{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('local[*]')\\\n",
    "        .appName('Homework9Part1')\\\n",
    "        .config('spark.driver.maxResultSize', '10g')\\\n",
    "        .config('spark.executor.memory' ,'10g')\\\n",
    "        .config('spark.driver.memory', '10g')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the train and test dataset\n",
    "* Train: `trainIdx2_matrix.txt`\n",
    "* Test: `testTrack_hierarchy.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- itemId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "\n",
    "train_schema = StructType([\n",
    "    StructField('userId', IntegerType()),\n",
    "    StructField('itemId', IntegerType()),\n",
    "    StructField('rating', DoubleType())\n",
    "])\n",
    "\n",
    "train = spark.read.csv('RawData/trainIdx2_matrix.txt',\n",
    "                       sep='|',\n",
    "                       header=False,\n",
    "                       schema=train_schema\n",
    "                      )\n",
    "\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|199808|248969|  90.0|\n",
      "|199808|  2663|  90.0|\n",
      "|199808| 28341|  90.0|\n",
      "|199808| 42563|  90.0|\n",
      "|199808| 59092|  90.0|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- trackId: integer (nullable = true)\n",
      " |-- albumId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- genreId_1: integer (nullable = true)\n",
      " |-- genreId_2: integer (nullable = true)\n",
      " |-- genreId_3: integer (nullable = true)\n",
      " |-- genreId_4: integer (nullable = true)\n",
      " |-- genreId_5: integer (nullable = true)\n",
      " |-- genreId_6: integer (nullable = true)\n",
      " |-- genreId_7: integer (nullable = true)\n",
      " |-- genreId_8: integer (nullable = true)\n",
      " |-- genreId_9: integer (nullable = true)\n",
      " |-- genreId_10: integer (nullable = true)\n",
      " |-- genreId_11: integer (nullable = true)\n",
      " |-- genreId_12: integer (nullable = true)\n",
      " |-- genreId_13: integer (nullable = true)\n",
      " |-- genreId_14: integer (nullable = true)\n",
      " |-- genreId_15: integer (nullable = true)\n",
      " |-- genreId_16: integer (nullable = true)\n",
      " |-- genreId_17: integer (nullable = true)\n",
      " |-- genreId_18: integer (nullable = true)\n",
      " |-- genreId_19: integer (nullable = true)\n",
      " |-- genreId_20: integer (nullable = true)\n",
      " |-- genreId_21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_schema = StructType([\n",
    "    StructField('userId', IntegerType()),\n",
    "    StructField('trackId', IntegerType()),\n",
    "    StructField('albumId', IntegerType()),\n",
    "    StructField('artistId', IntegerType()),\n",
    "    StructField('genreId_1', IntegerType()),\n",
    "    StructField('genreId_2', IntegerType()),\n",
    "    StructField('genreId_3', IntegerType()),\n",
    "    StructField('genreId_4', IntegerType()),\n",
    "    StructField('genreId_5', IntegerType()),\n",
    "    StructField('genreId_6', IntegerType()),\n",
    "    StructField('genreId_7', IntegerType()),\n",
    "    StructField('genreId_8', IntegerType()),\n",
    "    StructField('genreId_9', IntegerType()),\n",
    "    StructField('genreId_10', IntegerType()),\n",
    "    StructField('genreId_11', IntegerType()),\n",
    "    StructField('genreId_12', IntegerType()),\n",
    "    StructField('genreId_13', IntegerType()),\n",
    "    StructField('genreId_14', IntegerType()),\n",
    "    StructField('genreId_15', IntegerType()),\n",
    "    StructField('genreId_16', IntegerType()),\n",
    "    StructField('genreId_17', IntegerType()),\n",
    "    StructField('genreId_18', IntegerType()),\n",
    "    StructField('genreId_19', IntegerType()),\n",
    "    StructField('genreId_20', IntegerType()),\n",
    "    StructField('genreId_21', IntegerType()),\n",
    "])\n",
    "\n",
    "test = spark.read.csv('RawData/testTrack_hierarchy.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=test_schema)\n",
    "\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "|userId|trackId|artistId|genreId_1|genreId_2|genreId_3|genreId_4|genreId_5|\n",
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "|199810| 208019|    null|     null|     null|     null|     null|     null|\n",
      "|199810|  74139|  271146|   113360|   173467|   173655|   192976|   146792|\n",
      "|199810|   9903|    null|    33722|   123396|    79926|    73523|     null|\n",
      "|199810| 242681|  244574|    61215|    17453|   274088|     null|     null|\n",
      "|199810|  18515|   33168|    19913|    48505|   154024|     null|     null|\n",
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.select('userId', 'trackId', 'artistId', 'genreId_1', 'genreId_2', 'genreId_3', 'genreId_4', 'genreId_5').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only include the userIds that exist in the test dataset within the train dataset for the ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|199855|\n",
      "|199976|\n",
      "|200166|\n",
      "|200625|\n",
      "|200878|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "The number of unique users:  20000\n"
     ]
    }
   ],
   "source": [
    "test_unique_users = test.select('userId').distinct().coalesce(1)\n",
    "\n",
    "test_unique_users.show(5)\n",
    "print('The number of unique users: ', test_unique_users.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the trainset to only include userIds that are included within the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "train = train.toPandas()\n",
    "\n",
    "train = train[train.userId.isin(test_unique_users.toPandas().userId)]\n",
    "\n",
    "train = spark.createDataFrame(train).repartition('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: long (nullable = true)\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|200309| 88934| 100.0|\n",
      "|200309|293425| 100.0|\n",
      "|200309| 69014|  10.0|\n",
      "|200309| 28342|  80.0|\n",
      "|200309| 28964|  80.0|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|            userId|           itemId|            rating|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|          10643437|         10643437|          10643437|\n",
      "|   mean|224380.43626321084|149126.9231043506|47.600189769526516|\n",
      "| stddev|14393.139199046373| 85467.7984951211|37.996779529988316|\n",
      "|    min|            199810|                0|               0.0|\n",
      "|    max|            249010|           296110|             100.0|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(userCol='userId', \n",
    "          itemCol='itemId',\n",
    "          ratingCol='rating', \n",
    "          rank=5,\n",
    "          maxIter= 5,\n",
    "          regParam=0.01,\n",
    "          nonnegative = True, \n",
    "          implicitPrefs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+\n",
      "|userId|itemId|rating|prediction|\n",
      "+------+------+------+----------+\n",
      "|205890|   148|  90.0| 61.070606|\n",
      "|216277|   148|  90.0| 71.845634|\n",
      "|241707|   148|  60.0|    70.007|\n",
      "|226963|   148|  90.0|   76.1273|\n",
      "|206707|   148|  70.0|  62.11915|\n",
      "+------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  28.15705746813551\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "print('RMSE: ', evaluator.evaluate(train_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          10643437|\n",
      "|   mean|47.600189769526516|\n",
      "| stddev|  37.9967795299883|\n",
      "|    min|               0.0|\n",
      "|    max|             100.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results.select('rating').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for track, album, and artist on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values within `trackId`, `albumId`, and `artistId` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null trackId:  0\n",
      "Number of null albumId:  8572\n",
      "Number of null artistId:  10891\n"
     ]
    }
   ],
   "source": [
    "print('Number of null trackId: ', test.filter('trackId IS NULL').count())\n",
    "print('Number of null albumId: ', test.filter('albumId IS NULL').count())\n",
    "print('Number of null artistId: ', test.filter('artistId IS NULL').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on track ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_track = model.setItemCol('trackId').transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on album ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_album = model.setItemCol('albumId').transform(test.filter('albumId IS NOT NULL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on artist ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_artist = model.setItemCol('artistId').transform(test.filter('artistId IS NOT NULL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all ratings to the same dataframe, `predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "predictions = test.select('userId', 'trackId')\n",
    "\n",
    "predictions = predictions.join(prediction_track.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'track_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(prediction_album.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'album_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(prediction_artist.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'artist_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+------------+-------------+\n",
      "|userId|trackId|track_rating|album_rating|artist_rating|\n",
      "+------+-------+------------+------------+-------------+\n",
      "|200072|  29894|          75|          73|           76|\n",
      "|200124| 162126|           9|          10|           11|\n",
      "|200174| 137908|          25|          40|           35|\n",
      "|200400| 263168|          71|         100|           67|\n",
      "|200427|  82634|          10|          85|          116|\n",
      "+------+-------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values within the `track_rating`, `album_rating`, and `artist_rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null track_rating:  0\n",
      "Number of null album_rating:  8572\n",
      "Number of null artist_rating:  10891\n"
     ]
    }
   ],
   "source": [
    "print('Number of null track_rating: ', predictions.filter('track_rating IS NULL').count())\n",
    "print('Number of null album_rating: ', predictions.filter('album_rating IS NULL').count())\n",
    "print('Number of null artist_rating: ', predictions.filter('artist_rating IS NULL').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace null values within `album_rating` and `artist_rating` with `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of genres per userId-trackId pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genres = test.select('userId', \n",
    "                          'trackId', \n",
    "                          'genreId_1', \n",
    "                          'genreId_2', \n",
    "                          'genreId_3', \n",
    "                          'genreId_4', \n",
    "                          'genreId_5', \n",
    "                          'genreId_6', \n",
    "                          'genreId_7', \n",
    "                          'genreId_8', \n",
    "                          'genreId_9', \n",
    "                          'genreId_10', \n",
    "                          'genreId_11', \n",
    "                          'genreId_12', \n",
    "                          'genreId_13', \n",
    "                          'genreId_14',\n",
    "                          'genreId_15',\n",
    "                          'genreId_16',\n",
    "                          'genreId_17',\n",
    "                          'genreId_18',\n",
    "                          'genreId_19',\n",
    "                          'genreId_20',\n",
    "                          'genreId_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnull\n",
    "\n",
    "num_genres = test_genres.select('userId', 'trackId', sum([isnull(test_genres[col]).cast(IntegerType()) for col in test_genres.columns]).alias('num_genres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|trackId|num_genres|\n",
      "+------+-------+----------+\n",
      "|199810| 208019|        21|\n",
      "|199810|  74139|        14|\n",
      "|199810|   9903|        17|\n",
      "|199810| 242681|        18|\n",
      "|199810|  18515|        18|\n",
      "+------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_genres.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the number of genres into `predictions` dataframe, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(num_genres, ['userId', 'trackId'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+------------+-------------+----------+\n",
      "|userId|trackId|track_rating|album_rating|artist_rating|num_genres|\n",
      "+------+-------+------------+------------+-------------+----------+\n",
      "|200072|  29894|          75|          73|           76|        16|\n",
      "|200124| 162126|           9|          10|           11|        18|\n",
      "|200174| 137908|          25|          40|           35|        16|\n",
      "|200400| 263168|          71|         100|           67|        20|\n",
      "|200427|  82634|          10|          85|          116|        18|\n",
      "+------+-------+------------+------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `predictions` to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.coalesce(1).write.csv('Data/ratings.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
