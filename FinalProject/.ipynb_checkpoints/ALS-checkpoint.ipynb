{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9: Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('local[*]')\\\n",
    "        .appName('Homework9Part1')\\\n",
    "        .config('spark.driver.maxResultSize', '10g')\\\n",
    "        .config('spark.executor.memory' ,'10g')\\\n",
    "        .config('spark.driver.memory', '10g')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the train and test dataset\n",
    "* Train: `trainIdx2_matrix.txt`\n",
    "* Test: `testTrack_hierarchy.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- itemId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "\n",
    "train_schema = StructType([\n",
    "    StructField('userId', IntegerType()),\n",
    "    StructField('itemId', IntegerType()),\n",
    "    StructField('rating', DoubleType())\n",
    "])\n",
    "\n",
    "train = spark.read.csv('trainIdx2_matrix.txt',\n",
    "                       sep='|',\n",
    "                       header=False,\n",
    "                       schema=train_schema\n",
    "                      )\n",
    "\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|199808|248969|  90.0|\n",
      "|199808|  2663|  90.0|\n",
      "|199808| 28341|  90.0|\n",
      "|199808| 42563|  90.0|\n",
      "|199808| 59092|  90.0|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- trackId: integer (nullable = true)\n",
      " |-- albumId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- genreId_1: integer (nullable = true)\n",
      " |-- genreId_2: integer (nullable = true)\n",
      " |-- genreId_3: integer (nullable = true)\n",
      " |-- genreId_4: integer (nullable = true)\n",
      " |-- genreId_5: integer (nullable = true)\n",
      " |-- genreId_6: integer (nullable = true)\n",
      " |-- genreId_7: integer (nullable = true)\n",
      " |-- genreId_8: integer (nullable = true)\n",
      " |-- genreId_9: integer (nullable = true)\n",
      " |-- genreId_10: integer (nullable = true)\n",
      " |-- genreId_11: integer (nullable = true)\n",
      " |-- genreId_12: integer (nullable = true)\n",
      " |-- genreId_13: integer (nullable = true)\n",
      " |-- genreId_14: integer (nullable = true)\n",
      " |-- genreId_15: integer (nullable = true)\n",
      " |-- genreId_16: integer (nullable = true)\n",
      " |-- genreId_17: integer (nullable = true)\n",
      " |-- genreId_18: integer (nullable = true)\n",
      " |-- genreId_19: integer (nullable = true)\n",
      " |-- genreId_20: integer (nullable = true)\n",
      " |-- genreId_21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_schema = StructType([\n",
    "    StructField('userId', IntegerType()),\n",
    "    StructField('trackId', IntegerType()),\n",
    "    StructField('albumId', IntegerType()),\n",
    "    StructField('artistId', IntegerType()),\n",
    "    StructField('genreId_1', IntegerType()),\n",
    "    StructField('genreId_2', IntegerType()),\n",
    "    StructField('genreId_3', IntegerType()),\n",
    "    StructField('genreId_4', IntegerType()),\n",
    "    StructField('genreId_5', IntegerType()),\n",
    "    StructField('genreId_6', IntegerType()),\n",
    "    StructField('genreId_7', IntegerType()),\n",
    "    StructField('genreId_8', IntegerType()),\n",
    "    StructField('genreId_9', IntegerType()),\n",
    "    StructField('genreId_10', IntegerType()),\n",
    "    StructField('genreId_11', IntegerType()),\n",
    "    StructField('genreId_12', IntegerType()),\n",
    "    StructField('genreId_13', IntegerType()),\n",
    "    StructField('genreId_14', IntegerType()),\n",
    "    StructField('genreId_15', IntegerType()),\n",
    "    StructField('genreId_16', IntegerType()),\n",
    "    StructField('genreId_17', IntegerType()),\n",
    "    StructField('genreId_18', IntegerType()),\n",
    "    StructField('genreId_19', IntegerType()),\n",
    "    StructField('genreId_20', IntegerType()),\n",
    "    StructField('genreId_21', IntegerType()),\n",
    "])\n",
    "\n",
    "test = spark.read.csv('testTrack_hierarchy.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=test_schema)\n",
    "\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "|userId|trackId|artistId|genreId_1|genreId_2|genreId_3|genreId_4|genreId_5|\n",
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "|199810| 208019|    null|     null|     null|     null|     null|     null|\n",
      "|199810|  74139|  271146|   113360|   173467|   173655|   192976|   146792|\n",
      "|199810|   9903|    null|    33722|   123396|    79926|    73523|     null|\n",
      "|199810| 242681|  244574|    61215|    17453|   274088|     null|     null|\n",
      "|199810|  18515|   33168|    19913|    48505|   154024|     null|     null|\n",
      "+------+-------+--------+---------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.select('userId', 'trackId', 'artistId', 'genreId_1', 'genreId_2', 'genreId_3', 'genreId_4', 'genreId_5').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only include the userIds that exist in the test dataset within the train dataset for the ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|199855|\n",
      "|199976|\n",
      "|200166|\n",
      "|200625|\n",
      "|200878|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "The number of unique users:  20000\n"
     ]
    }
   ],
   "source": [
    "test_unique_users = test.select('userId').distinct().coalesce(1)\n",
    "\n",
    "test_unique_users.show(5)\n",
    "print('The number of unique users: ', test_unique_users.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the trainset to only include userIds that are included within the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', 'true')\n",
    "\n",
    "train = train.toPandas()\n",
    "\n",
    "train = train[train.userId.isin(test_unique_users.toPandas().userId)]\n",
    "\n",
    "train = spark.createDataFrame(train).repartition('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- itemId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|199855| 33722|   0.0|\n",
      "|199855|274161|   0.0|\n",
      "|199855|113360|   0.0|\n",
      "|199855|149962|   0.0|\n",
      "|199855|155264|   0.0|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|            userId|           itemId|            rating|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|          10643437|         10643437|          10643437|\n",
      "|   mean|224380.43626321084|149126.9231043506|47.600189769526516|\n",
      "| stddev|14393.139199046505|85467.79849512114| 37.99677952998833|\n",
      "|    min|            199810|                0|               0.0|\n",
      "|    max|            249010|           296110|             100.0|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(userCol='userId', \n",
    "          itemCol='itemId',\n",
    "          ratingCol='rating', \n",
    "          rank=5,\n",
    "          maxIter= 5,\n",
    "          regParam=0.01,\n",
    "          nonnegative = True, \n",
    "          implicitPrefs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+\n",
      "|userId|itemId|rating|prediction|\n",
      "+------+------+------+----------+\n",
      "|205890|   148|  90.0|  67.68551|\n",
      "|216277|   148|  90.0|  73.53194|\n",
      "|241707|   148|  60.0|  75.45129|\n",
      "|226963|   148|  90.0|  65.46061|\n",
      "|206707|   148|  70.0|  65.30318|\n",
      "+------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  28.553197559911332\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "\n",
    "print('RMSE: ', evaluator.evaluate(train_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            rating|\n",
      "+-------+------------------+\n",
      "|  count|          10643437|\n",
      "|   mean|47.600189769526516|\n",
      "| stddev|  37.9967795299883|\n",
      "|    min|               0.0|\n",
      "|    max|             100.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results.select('rating').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for track, album, and artist on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values within `trackId`, `albumId`, and `artistId` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null trackId:  0\n",
      "Number of null albumId:  8572\n",
      "Number of null artistId:  10891\n"
     ]
    }
   ],
   "source": [
    "print('Number of null trackId: ', test.filter('trackId IS NULL').count())\n",
    "print('Number of null albumId: ', test.filter('albumId IS NULL').count())\n",
    "print('Number of null artistId: ', test.filter('artistId IS NULL').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on track ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_track = model.setItemCol('trackId').transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on album ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_album = model.setItemCol('albumId').transform(test.filter('albumId IS NOT NULL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on artist ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_artist = model.setItemCol('artistId').transform(test.filter('artistId IS NOT NULL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all ratings to the same dataframe, `predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "predictions = test.select('userId', 'trackId')\n",
    "\n",
    "predictions = predictions.join(prediction_track.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'track_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(prediction_album.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'album_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(prediction_artist.select('userId', 'trackId', 'prediction'), ['userId', 'trackId'], 'left')\n",
    "\n",
    "predictions = predictions.withColumn('prediction', predictions['prediction'].cast(IntegerType()))\\\n",
    "                         .withColumnRenamed('prediction', 'artist_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+------------+-------------+\n",
      "|userId|trackId|track_rating|album_rating|artist_rating|\n",
      "+------+-------+------------+------------+-------------+\n",
      "|200072|  29894|          67|          66|           75|\n",
      "|200124| 162126|          11|          11|           12|\n",
      "|200174| 137908|          45|          33|           31|\n",
      "|200400| 263168|          67|          60|           29|\n",
      "|200427|  82634|          73|          78|           61|\n",
      "+------+-------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values within the `track_rating`, `album_rating`, and `artist_rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null track_rating:  0\n",
      "Number of null album_rating:  8572\n",
      "Number of null artist_rating:  10891\n"
     ]
    }
   ],
   "source": [
    "print('Number of null track_rating: ', predictions.filter('track_rating IS NULL').count())\n",
    "print('Number of null album_rating: ', predictions.filter('album_rating IS NULL').count())\n",
    "print('Number of null artist_rating: ', predictions.filter('artist_rating IS NULL').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace null values within `album_rating` and `artist_rating` with `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of genres per userId-trackId pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genres = test.select('userId', \n",
    "                          'trackId', \n",
    "                          'genreId_1', \n",
    "                          'genreId_2', \n",
    "                          'genreId_3', \n",
    "                          'genreId_4', \n",
    "                          'genreId_5', \n",
    "                          'genreId_6', \n",
    "                          'genreId_7', \n",
    "                          'genreId_8', \n",
    "                          'genreId_9', \n",
    "                          'genreId_10', \n",
    "                          'genreId_11', \n",
    "                          'genreId_12', \n",
    "                          'genreId_13', \n",
    "                          'genreId_14',\n",
    "                          'genreId_15',\n",
    "                          'genreId_16',\n",
    "                          'genreId_17',\n",
    "                          'genreId_18',\n",
    "                          'genreId_19',\n",
    "                          'genreId_20',\n",
    "                          'genreId_21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnull\n",
    "\n",
    "num_genres = test_genres.select('userId', 'trackId', sum([isnull(test_genres[col]).cast(IntegerType()) for col in test_genres.columns]).alias('num_genres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|trackId|num_genres|\n",
      "+------+-------+----------+\n",
      "|199810| 208019|        21|\n",
      "|199810|  74139|        14|\n",
      "|199810|   9903|        17|\n",
      "|199810| 242681|        18|\n",
      "|199810|  18515|        18|\n",
      "+------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_genres.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the number of genres into `predictions` dataframe, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(num_genres, ['userId', 'trackId'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+------------+-------------+----------+\n",
      "|userId|trackId|track_rating|album_rating|artist_rating|num_genres|\n",
      "+------+-------+------------+------------+-------------+----------+\n",
      "|200072|  29894|          67|          66|           75|        16|\n",
      "|200124| 162126|          11|          11|           12|        18|\n",
      "|200174| 137908|          45|          33|           31|        16|\n",
      "|200400| 263168|          67|          60|           29|        20|\n",
      "|200427|  82634|          73|          78|           61|        18|\n",
      "+------+-------+------------+------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `predictions` to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.coalesce(1).write.csv('ratings.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the track, album, and artist data\n",
    "* Track Data: `trackData2.txt`\n",
    "* Album Data: `albumData2.txt`\n",
    "* Artist Data: `artistData2.txt`\n",
    "* Genre Data: `genreData2.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trackId: integer (nullable = true)\n",
      " |-- albumId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- genreId_1: integer (nullable = true)\n",
      " |-- genreId_2: integer (nullable = true)\n",
      " |-- genreId_3: integer (nullable = true)\n",
      " |-- genreId_4: integer (nullable = true)\n",
      " |-- genreId_5: integer (nullable = true)\n",
      " |-- genreId_6: integer (nullable = true)\n",
      " |-- genreId_7: integer (nullable = true)\n",
      " |-- genreId_8: integer (nullable = true)\n",
      " |-- genreId_9: integer (nullable = true)\n",
      " |-- genreId_10: integer (nullable = true)\n",
      " |-- genreId_11: integer (nullable = true)\n",
      " |-- genreId_12: integer (nullable = true)\n",
      " |-- genreId_13: integer (nullable = true)\n",
      " |-- genreId_14: integer (nullable = true)\n",
      " |-- genreId_15: integer (nullable = true)\n",
      " |-- genreId_16: integer (nullable = true)\n",
      " |-- genreId_17: integer (nullable = true)\n",
      " |-- genreId_18: integer (nullable = true)\n",
      " |-- genreId_19: integer (nullable = true)\n",
      " |-- genreId_20: integer (nullable = true)\n",
      " |-- genreId_21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "track_schema = StructType([\n",
    "    StructField('trackId', IntegerType()),\n",
    "    StructField('albumId', IntegerType()),\n",
    "    StructField('artistId', IntegerType()),\n",
    "    StructField('genreId_1', IntegerType()),\n",
    "    StructField('genreId_2', IntegerType()),\n",
    "    StructField('genreId_3', IntegerType()),\n",
    "    StructField('genreId_4', IntegerType()),\n",
    "    StructField('genreId_5', IntegerType()),\n",
    "    StructField('genreId_6', IntegerType()),\n",
    "    StructField('genreId_7', IntegerType()),\n",
    "    StructField('genreId_8', IntegerType()),\n",
    "    StructField('genreId_9', IntegerType()),\n",
    "    StructField('genreId_10', IntegerType()),\n",
    "    StructField('genreId_11', IntegerType()),\n",
    "    StructField('genreId_12', IntegerType()),\n",
    "    StructField('genreId_13', IntegerType()),\n",
    "    StructField('genreId_14', IntegerType()),\n",
    "    StructField('genreId_15', IntegerType()),\n",
    "    StructField('genreId_16', IntegerType()),\n",
    "    StructField('genreId_17', IntegerType()),\n",
    "    StructField('genreId_18', IntegerType()),\n",
    "    StructField('genreId_19', IntegerType()),\n",
    "    StructField('genreId_20', IntegerType()),\n",
    "    StructField('genreId_21', IntegerType()),\n",
    "])\n",
    "\n",
    "track = spark.read.csv('trackData2.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=track_schema)\n",
    "\n",
    "track.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- albumId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- genreId_1: integer (nullable = true)\n",
      " |-- genreId_2: integer (nullable = true)\n",
      " |-- genreId_3: integer (nullable = true)\n",
      " |-- genreId_4: integer (nullable = true)\n",
      " |-- genreId_5: integer (nullable = true)\n",
      " |-- genreId_6: integer (nullable = true)\n",
      " |-- genreId_7: integer (nullable = true)\n",
      " |-- genreId_8: integer (nullable = true)\n",
      " |-- genreId_9: integer (nullable = true)\n",
      " |-- genreId_10: integer (nullable = true)\n",
      " |-- genreId_11: integer (nullable = true)\n",
      " |-- genreId_12: integer (nullable = true)\n",
      " |-- genreId_13: integer (nullable = true)\n",
      " |-- genreId_14: integer (nullable = true)\n",
      " |-- genreId_15: integer (nullable = true)\n",
      " |-- genreId_16: integer (nullable = true)\n",
      " |-- genreId_17: integer (nullable = true)\n",
      " |-- genreId_18: integer (nullable = true)\n",
      " |-- genreId_19: integer (nullable = true)\n",
      " |-- genreId_20: integer (nullable = true)\n",
      " |-- genreId_21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "album_schema = StructType([\n",
    "    StructField('albumId', IntegerType()),\n",
    "    StructField('artistId', IntegerType()),\n",
    "    StructField('genreId_1', IntegerType()),\n",
    "    StructField('genreId_2', IntegerType()),\n",
    "    StructField('genreId_3', IntegerType()),\n",
    "    StructField('genreId_4', IntegerType()),\n",
    "    StructField('genreId_5', IntegerType()),\n",
    "    StructField('genreId_6', IntegerType()),\n",
    "    StructField('genreId_7', IntegerType()),\n",
    "    StructField('genreId_8', IntegerType()),\n",
    "    StructField('genreId_9', IntegerType()),\n",
    "    StructField('genreId_10', IntegerType()),\n",
    "    StructField('genreId_11', IntegerType()),\n",
    "    StructField('genreId_12', IntegerType()),\n",
    "    StructField('genreId_13', IntegerType()),\n",
    "    StructField('genreId_14', IntegerType()),\n",
    "    StructField('genreId_15', IntegerType()),\n",
    "    StructField('genreId_16', IntegerType()),\n",
    "    StructField('genreId_17', IntegerType()),\n",
    "    StructField('genreId_18', IntegerType()),\n",
    "    StructField('genreId_19', IntegerType()),\n",
    "    StructField('genreId_20', IntegerType()),\n",
    "    StructField('genreId_21', IntegerType()),\n",
    "])\n",
    "\n",
    "album = spark.read.csv('albumData2.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=album_schema)\n",
    "\n",
    "album.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- albumId: integer (nullable = true)\n",
      " |-- artistId: integer (nullable = true)\n",
      " |-- genreId_1: integer (nullable = true)\n",
      " |-- genreId_2: integer (nullable = true)\n",
      " |-- genreId_3: integer (nullable = true)\n",
      " |-- genreId_4: integer (nullable = true)\n",
      " |-- genreId_5: integer (nullable = true)\n",
      " |-- genreId_6: integer (nullable = true)\n",
      " |-- genreId_7: integer (nullable = true)\n",
      " |-- genreId_8: integer (nullable = true)\n",
      " |-- genreId_9: integer (nullable = true)\n",
      " |-- genreId_10: integer (nullable = true)\n",
      " |-- genreId_11: integer (nullable = true)\n",
      " |-- genreId_12: integer (nullable = true)\n",
      " |-- genreId_13: integer (nullable = true)\n",
      " |-- genreId_14: integer (nullable = true)\n",
      " |-- genreId_15: integer (nullable = true)\n",
      " |-- genreId_16: integer (nullable = true)\n",
      " |-- genreId_17: integer (nullable = true)\n",
      " |-- genreId_18: integer (nullable = true)\n",
      " |-- genreId_19: integer (nullable = true)\n",
      " |-- genreId_20: integer (nullable = true)\n",
      " |-- genreId_21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_schema = StructType([\n",
    "    StructField('artistId', IntegerType()),\n",
    "    StructField('genreId_1', IntegerType()),\n",
    "    StructField('genreId_2', IntegerType()),\n",
    "    StructField('genreId_3', IntegerType()),\n",
    "    StructField('genreId_4', IntegerType()),\n",
    "    StructField('genreId_5', IntegerType()),\n",
    "    StructField('genreId_6', IntegerType()),\n",
    "    StructField('genreId_7', IntegerType()),\n",
    "    StructField('genreId_8', IntegerType()),\n",
    "    StructField('genreId_9', IntegerType()),\n",
    "    StructField('genreId_10', IntegerType()),\n",
    "    StructField('genreId_11', IntegerType()),\n",
    "    StructField('genreId_12', IntegerType()),\n",
    "    StructField('genreId_13', IntegerType()),\n",
    "    StructField('genreId_14', IntegerType()),\n",
    "    StructField('genreId_15', IntegerType()),\n",
    "    StructField('genreId_16', IntegerType()),\n",
    "    StructField('genreId_17', IntegerType()),\n",
    "    StructField('genreId_18', IntegerType()),\n",
    "    StructField('genreId_19', IntegerType()),\n",
    "    StructField('genreId_20', IntegerType()),\n",
    "    StructField('genreId_21', IntegerType()),\n",
    "])\n",
    "\n",
    "artist = spark.read.csv('artistData2.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=artist_schema)\n",
    "\n",
    "album.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genreId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_schema = StructType([\n",
    "    StructField('genreId', IntegerType()),\n",
    "])\n",
    "\n",
    "genre = spark.read.csv('genreData2.txt',\n",
    "                     sep='|',\n",
    "                     nullValue='None',\n",
    "                     header=False,\n",
    "                     schema=genre_schema)\n",
    "\n",
    "genre.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the `track`, `album`, `artist`, and `genre` hierarchy of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train.select('userId', 'itemId', 'rating').coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+---+\n",
      "|userId|itemId|rating| id|\n",
      "+------+------+------+---+\n",
      "|199855| 33722|   0.0|  0|\n",
      "|199855|274161|   0.0|  1|\n",
      "|199855|113360|   0.0|  2|\n",
      "|199855|149962|   0.0|  3|\n",
      "|199855|155264|   0.0|  4|\n",
      "+------+------+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "train_ids = train_ids.withColumn('id', monotonically_increasing_id()).persist()\n",
    "\n",
    "train_ids.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `track`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hierarchy_track = train_ids.join(track.withColumnRenamed('trackId', 'itemId'), 'itemId', 'leftsemi')\n",
    "train_hierarchy_track = train_hierarchy_track.withColumnRenamed('itemId', 'trackId').withColumnRenamed('rating', 'track_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+---+\n",
      "|userId|trackId|track_rating| id|\n",
      "+------+-------+------------+---+\n",
      "|199855| 146264|       100.0| 28|\n",
      "|199855|  38015|       100.0| 33|\n",
      "|199855|  18433|       100.0| 36|\n",
      "|199855|  34230|       100.0| 37|\n",
      "|199855|  60468|       100.0| 38|\n",
      "+------+-------+------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hierarchy_track.select('userId', 'trackId', 'track_rating', 'id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `album`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hierarchy_album = train_ids.join(album.withColumnRenamed('albumId', 'itemId'), 'itemId', 'leftsemi')\n",
    "train_hierarchy_album = train_hierarchy_album.withColumnRenamed('itemId', 'albumId').withColumnRenamed('rating', 'album_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+---+\n",
      "|userId|albumId|album_rating| id|\n",
      "+------+-------+------------+---+\n",
      "|199855|  66885|         0.0| 23|\n",
      "|199855| 227229|       100.0| 35|\n",
      "|199855|   8685|       100.0| 45|\n",
      "|199855| 278330|       100.0| 56|\n",
      "|199855| 190393|        90.0| 97|\n",
      "+------+-------+------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hierarchy_album.select('userId', 'albumId', 'album_rating', 'id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `artist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hierarchy_artist = train_ids.join(artist.withColumnRenamed('artistId', 'itemId'), 'itemId', 'leftsemi')\n",
    "train_hierarchy_artist = train_hierarchy_artist.withColumnRenamed('itemId', 'artistId').withColumnRenamed('rating', 'artist_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+---+\n",
      "|userId|artistId|artist_rating| id|\n",
      "+------+--------+-------------+---+\n",
      "|199855|  154852|         70.0| 16|\n",
      "|199855|  163015|          0.0| 18|\n",
      "|199855|  285087|          0.0| 19|\n",
      "|199855|   44857|          0.0| 20|\n",
      "|199855|  212235|          0.0| 21|\n",
      "+------+--------+-------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hierarchy_artist.select('userId', 'artistId' , 'artist_rating', 'id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `genre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hierarchy_genre = train_ids.join(genre.withColumnRenamed('genreId', 'itemId'), 'itemId', 'leftsemi')\n",
    "train_hierarchy_genre = train_hierarchy_genre.withColumnRenamed('itemId', 'genreId').withColumnRenamed('rating', 'genre_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+---+\n",
      "|userId|genreId|genre_rating| id|\n",
      "+------+-------+------------+---+\n",
      "|199855|  33722|         0.0|  0|\n",
      "|199855| 274161|         0.0|  1|\n",
      "|199855| 113360|         0.0|  2|\n",
      "|199855| 149962|         0.0|  3|\n",
      "|199855| 155264|         0.0|  4|\n",
      "+------+-------+------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hierarchy_genre.select('userId', 'genreId' , 'genre_rating', 'id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join together:\n",
    "* `train_hierarchy_track`\n",
    "* `train_hierarchy_album` \n",
    "* `train_hierarchy_artist` \n",
    "\n",
    "to make `train_hierarchy` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hierarchy = train_ids.select('id', 'userId')\n",
    "\n",
    "train_hierarchy = train_hierarchy.join(train_hierarchy_track.select('id', 'track_rating', 'trackId'), 'id', 'left')\n",
    "train_hierarchy = train_hierarchy.join(train_hierarchy_artist.select('id', 'artist_rating', 'artistId'), 'id', 'left')\n",
    "train_hierarchy = train_hierarchy.join(train_hierarchy_genre.select('id', 'genre_rating', 'genreId'), 'id', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+-------+-------------+--------+------------+-------+\n",
      "| id|userId|track_rating|trackId|artist_rating|artistId|genre_rating|genreId|\n",
      "+---+------+------------+-------+-------------+--------+------------+-------+\n",
      "|  0|199855|        null|   null|         null|    null|         0.0|  33722|\n",
      "|  1|199855|        null|   null|         null|    null|         0.0| 274161|\n",
      "|  2|199855|        null|   null|         null|    null|         0.0| 113360|\n",
      "|  3|199855|        null|   null|         null|    null|         0.0| 149962|\n",
      "|  4|199855|        null|   null|         null|    null|         0.0| 155264|\n",
      "+---+------+------------+-------+-------------+--------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_hierarchy.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
